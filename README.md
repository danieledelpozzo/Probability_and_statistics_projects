# Probability & Statistics projects
A collection of university projects demonstrating applied probability, statistical modeling, simulations, and data analysis.



# Project 1 â€“ Pseudo-Random Number Generators & Wattsâ€“Strogatz Model

This project explores pseudo-random number generation, Bernoulli trials, random adjacency matrices, and the Wattsâ€“Strogatz small-world model.



ðŸ“Œ Contents of the Notebook

1. Linear Congruential Generator (LCG)
	â€¢	Implementation of LCG with different configurations
	â€¢	Comparison of periodicity and distribution
	â€¢	Histograms of generated values

2. Middle-Square Method
	â€¢	Classic MSM implementation
	â€¢	Demonstration of rapid cycle collapse
	â€¢	Visualization of output distributions

3. Bernoulli Variable Simulation
	â€¢	Generation of uniform random variables using LCG
	â€¢	Transformation into Bernoulli(p) variables
	â€¢	Construction of a symmetric 100Ã—100 adjacency matrix

4. Random Graph Construction
	â€¢	Building a graph in igraph from the adjacency matrix
	â€¢	Analysis of connectivity and structure

5. Wattsâ€“Strogatz Model
	â€¢	Generation of a small-world network
	â€¢	Exploration of clustering and path length





# Project 2 - Knightâ€™s Movement Markov Chain â€“ Stationary Distribution & Return Times

This project models the movement of a knight on a standard 8Ã—8 chessboard using a Markov Chain.





ðŸ“Œ Contents of the Notebook

1. Knight Movement Model
	â€¢	Representation of the chessboard as an 8Ã—8 grid
	â€¢	Definition of all legal knight moves
	â€¢	Computation of the number of legal moves per square (Matrix C)

2. Adjacency Matrix Construction
	â€¢	Creation of the 64Ã—64 adjacency matrix (A)
	â€¢	Encoding legal knight moves as directed edges
	â€¢	Mapping chessboard coordinates to matrix indices

3. Degree and Transition Matrices
	â€¢	Construction of the degree matrix (D) and degree vector (d)
	â€¢	Definition of the transition matrix (P) with uniform move probabilities
	â€¢	Verification of row-stochastic properties and connectivity

4. Random Walk Simulation
	â€¢	Execution of a 100,000-step knight random walk
	â€¢	Tracking visit counts to each square
	â€¢	Normalization to obtain the empirical stationary distribution (S)

5. Stationary Distribution & Return Times
	â€¢	Interpretation of S as the long-run occupation frequency
	â€¢	Calculation of average return times (R) using reciprocity
	â€¢	Comparison between board regions (corners, edges, center)





# Project 3 - Housing Price Prediction with Bootstrap Regression

This project focuses on predicting housing prices using a real dataset. It covers exploratory data analysis, train-test splitting, and statistical modeling using a bootstrap procedure to assess model variability and coefficient stability.


ðŸ“Œ Contents of the Notebook

1. Dataset Import & Preparation
	â€¢	Loading the Boston Housing dataset from CSV
	â€¢	Extracting predictors (X) and target variable (medv)
	â€¢	Setting a deterministic random seed based on a student ID
	â€¢	Splitting the dataset into 90% training and 10% test subsets

2. Exploratory Data Analysis (EDA)
	â€¢	Scatterplot analysis of the relationship between average number of rooms (rm) and housing prices (medv)
	â€¢	Preliminary inspection of dataset structure and descriptive patterns
	â€¢	Identification of correlations useful for regression modeling

3. Trainâ€“Test Split Procedure
	â€¢	Manual index-based sampling for the 90â€“10 split
	â€¢	Verification of subset sizes and distribution of samples
	â€¢	Alternative split using train_test_split() from scikit-learn

4. Bootstrap Estimation of Regression Coefficients
	â€¢	Implementation of a bootstrap resampling procedure (1,000 iterations)
	â€¢	Resampling of the training dataset with replacement
	â€¢	Fitting linear regression models using statsmodels OLS
	â€¢	Storage and aggregation of bootstrap-derived coefficient estimates

5. Model Interpretation & Stability Analysis
	â€¢	Assessment of coefficient variability across bootstrap samples
	â€¢	Evaluation of model robustness and sensitivity to sampling variation
	â€¢	Preparation for confidence interval estimation (if extended)



# Project 4 â€” Diabetes Prediction Model with Logistic Regression and Neural Networks

This project focuses on predicting diabetes outcomes using clinical data. It combines classical logistic regression with a simple neural network model, including exploratory data analysis, dataset splitting, and model evaluation.

ðŸ“Œ Contents of the Notebook

1. Exploratory Analysis
	â€¢	Importing and inspecting the dataset (diabetes.csv)
	â€¢	Visualization of feature relationships using pair plots
	â€¢	Identifying trends and patterns in predictors and the outcome

2. Data Preparation
	â€¢	Splitting the dataset into training (90%) and test (10%) sets
	â€¢	Ensuring reproducibility using student-specific random seed
	â€¢	Defining predictors (X) and target variable (Outcome)

3. Logistic Regression Model
	â€¢	Fitting a logistic regression model to predict diabetes outcomes
	â€¢	Evaluating model performance and coefficients
	â€¢	Comparing results with baseline expectations

4. Neural Network Model
	â€¢	Defining a simple feed-forward neural network for binary classification
	â€¢	Using sigmoid activation and binary cross-entropy loss
	â€¢	Compiling with the Adam optimizer
	â€¢	Training the network on the prepared dataset

5. Model Interpretation
	â€¢	Comparing predictions from logistic regression and neural network
	â€¢	Assessing model accuracy and suitability for clinical data
	â€¢	Visualizing results to support insights and conclusions


